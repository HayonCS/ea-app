/**
 * This module provides tooling for implementing Repositories backed by knex.
 *
 * Repositories are generated from a `RecordInfo` which captures name, primary
 * key, and type information about the rows of the table. These `RecordInfo`
 * values drive the CRUD operations built into a repository and also allow
 * automatic generation of Dataloaders for relationships between tables.
 *
 * As a general rule, you want a `RecordInfo` for each table and a `Repository`
 * for it. You can then use `loaderOf(this)` within the repository to generate
 * dataloaders for common relationships and lookup needs. See the methods on
 * `LoaderFactory` for available dataloader generators.
 *
 * The dataloaders generated by the helpers have a special property: they use
 * the base finder data loader as the source of truth for record objects. Thus
 * every JavaScript object representing row with ID X within a particular
 * dependency injection context should be the same instance, no matter which
 * dataloader fetched it. This is to reduce the likelihood of mutations to that
 * object leading to inconsistencies across dataloaders, as well as reduce RAM
 * use. Generally this is transparent, but important to keep in mind. See the
 * `primeAll` method below
 */

import * as DataLoader from "dataloader";
import * as _ from "lodash-es";
import * as db from "db";
import * as knex from "knex";
import * as stringify from "json-stable-stringify";

import { EntityType, KeyType, SavedR, UnsavedR } from "../abstract";
import { at, compact, groupBy, keyBy, pick } from "lodash-es";

import { Context } from "atomic-object/hexagonal/context";
import { KnexPort } from "atomic-object/records/knex/ports";
import { escapeSqlString, escapeBindingSyntax } from "./helpers";

type MinimalContext = Context<KnexPort>;

export type Knex = knex.Knex;

export type IsolationLevel =
  | "READ UNCOMMITTED"
  | "READ COMMITTED"
  | "REPEATABLE READ"
  | "SERIALIZABLE";

export type Domain = "Production" | "Engineering";

export interface KnexRecordInfo<
  Unsaved = any,
  Saved = any,
  IdType extends object = any
> extends EntityType<Unsaved, Saved, IdType> {
  tableName: string;
  idKeys: (keyof Saved)[];
}

/** Extract the runtime key name from a recordInfo */
export function idKeysOf<RI extends KnexRecordInfo>(
  recordInfoWithIdKey: RI
): string[] {
  return recordInfoWithIdKey.idKeys as any;
}

function castToRecordInfo(
  runtimeData: Omit<KnexRecordInfo, "_idKeys" | "_saved" | "_unsaved">
): KnexRecordInfo {
  return runtimeData as KnexRecordInfo;
}

/** Creates a record descriptor that captures the table name, primary key name, unsaved type, and saved type of a database record type. Assumes "id" as the primary key name */
export function recordInfo<Unsaved, Saved extends { id: any }>(
  tableName: string
): KnexRecordInfo<Unsaved, Saved, Pick<Saved, "id">>;

export function recordInfo<Type extends { id: string }>(
  tableName: string
): KnexRecordInfo<Type, Type, Pick<Type, "id">>;

/** Creates a record descriptor that captures the table name, primary key name, unsaved type, and saved type of a database record type. */
export function recordInfo<Unsaved, Saved, Id extends keyof Saved>(
  tableName: string,
  idKey: Id[]
): KnexRecordInfo<Unsaved, Saved, Pick<Saved, Id>>;

/** Don't use this signature – be sure to provide unsaved and saved types. */
export function recordInfo(tableName: string, idKeys?: string[]) {
  idKeys = idKeys || ["id"];
  return castToRecordInfo({
    tableName,
    idKeys: idKeys,
    idOf: (rec) => pick(rec, idKeys as any),
  });
}

export function recordType<TUnsaved, TSaved = TUnsaved>(
  tableName: string
): {
  withCompositeKeys<TKeys extends keyof TSaved>(
    keys: TKeys[]
  ): KnexRecordInfo<TUnsaved, TSaved, Pick<TSaved, TKeys>>;
} {
  return {
    withCompositeKeys(keys) {
      return castToRecordInfo({
        tableName,
        idKeys: keys,
        idOf: (rec) => pick(rec, keys),
      });
    },
  };
}

export class LoaderFactory<
  TContext extends MinimalContext,
  UnsavedDestType,
  SavedDestType,
  DestId extends object
> {
  constructor(
    public readonly repo: KnexRepositoryBase<
      TContext,
      KnexRecordInfo<UnsavedDestType, SavedDestType, DestId>
    >
  ) {}

  /** Generates a dataloader that finds a record uniquely identified by the provided value of the target key. This field should have a unique index. */
  findOneBy<K extends keyof SavedDestType>(targetKey: K) {
    return new DataLoader<SavedDestType[K], SavedDestType | null>(
      async (keyValues: any) => {
        const entries: SavedDestType[] = await this._primeAll(
          await this.repo.table().whereIn(targetKey as any, keyValues as any)
        );
        const table = keyBy(entries, targetKey);
        return keyValues.map((val: any) => table[val.toString()] || null);
      },
      {
        cacheKeyFn: stringify as any,
      }
    );
  }

  /** Generates a dataloader that finds a record identified by a composite of the provided keys. */
  findOneByColumns<K extends keyof SavedDestType>(targetKeys: K[]) {
    return new DataLoader<{ [k in K]: SavedDestType[k] }, SavedDestType | null>(
      async (keyValues) => {
        const entries: SavedDestType[] = await this._primeAll(
          await this.repo
            .table()
            .whereIn(
              targetKeys as any[],
              keyValues.map((vals) => targetKeys.map((k) => vals[k])) as any[][]
            )
        );
        const table = keyBy(entries, (r) =>
          targetKeys.map((k) => r[k]).join("-")
        );
        return keyValues.map(
          (vals) => table[targetKeys.map((k) => vals[k]).join("-")] || null
        );
      },
      {
        cacheKeyFn: stringify as any,
      }
    );
  }

  findOneByWithDefault<K extends keyof SavedDestType>(
    targetKey: K,
    buildDefault: (keyValues: any) => SavedDestType[]
  ) {
    return new DataLoader<SavedDestType[K], SavedDestType>(
      async (keyValues: any) => {
        let foundEntries = await this.repo
          .table()
          .whereIn(targetKey as any, keyValues as any);
        if (foundEntries.length === 0) {
          foundEntries = buildDefault(keyValues);
        }
        const entries: SavedDestType[] = await this._primeAll(foundEntries);
        const table = keyBy(entries, targetKey);
        return keyValues.map((val: any) => table[val.toString()] || null);
      },
      {
        cacheKeyFn: stringify as any,
      }
    );
  }

  findManyByColumns<K extends keyof SavedDestType>(targetKeys: K[]) {
    return new DataLoader<{ [k in K]: SavedDestType[K] }, SavedDestType[]>(
      async (keyValues) => {
        const entries: SavedDestType[] = await this._primeAll(
          await this.repo
            .table()
            .whereIn(
              targetKeys as any[],
              keyValues.map((vals) => targetKeys.map((k) => vals[k])) as any[][]
            )
        );
        const table = groupBy<SavedDestType>(entries, (r) =>
          targetKeys.map((k) => r[k]).join("-")
        );
        return keyValues.map(
          (vals) => table[targetKeys.map((k) => vals[k]).join("-")] || []
        );
      },
      {
        cacheKeyFn: stringify as any,
      }
    );
  }

  findManyBy<K extends keyof SavedDestType>(targetKey: K) {
    return new DataLoader<SavedDestType[K], SavedDestType[]>(
      async (keyValues: any) => {
        const entries: SavedDestType[] = await this._primeAll(
          await this.repo.table().whereIn(targetKey as any, keyValues)
        );
        const table = groupBy<SavedDestType>(entries, targetKey);
        const ordered = keyValues.map(
          (keyValue: any) => table[keyValue.toString()] || []
        );
        return ordered;
      },
      {
        cacheKeyFn: stringify as any,
      }
    );
  }

  /** Analogous to has_many in Rails */
  allBelongingTo<
    UnsavedSourceT,
    SavedSourceT,
    SourceId extends object,
    K extends keyof SavedDestType
  >(
    record: KnexRecordInfo<UnsavedSourceT, SavedSourceT, SourceId>,
    foreignKey: K
  ) {
    // type SourceRecord = SavedR<typeof record>;
    type IdType = KeyType<typeof record>;
    if (record.idKeys.length > 1) {
      throw new Error("allBelongingTo doesn't support compound primary keys");
    }
    return new DataLoader<IdType, SavedDestType[]>(
      async (args) => {
        // TBD batch these to avoid max SQL string lengths?
        const ids: IdType[] = args.map(
          (arg) => (arg as any)[record.idKeys[0]] as any
        );

        const records: any[] = [];

        const MAX_PARAMETERS = 1500;

        const chunkSize = MAX_PARAMETERS;

        const idsChunks = _.chunk(ids, chunkSize);

        for (const idsChunk of idsChunks) {
          records.push(
            ...(await this._primeAll(
              await this.repo
                .table()
                .whereIn(foreignKey as any, idsChunk as any[])
            ))
          );
        }

        const table = groupBy<SavedDestType>(records, foreignKey as any);
        const ordered = ids.map((id) => table[(id as any).toString()] || []);
        return ordered;
      },
      {
        cacheKeyFn: stringify as any,
      }
    );
  }

  /** Analogous to has_one in Rails */
  oneBelongingTo<
    SourceRecordInfo extends KnexRecordInfo<any, any, any>,
    ForeignKey extends keyof SavedDestType
  >(record: SourceRecordInfo, foreignKey: ForeignKey) {
    if (record.idKeys.length > 1) {
      throw new Error("oneBelongingTo doesn't support compound primary keys");
    }
    type SourceRecord = SavedR<typeof record>;
    type FkType = SavedDestType[ForeignKey];
    return new DataLoader<SourceRecord | FkType, SavedDestType>(
      async (args) => {
        const ids: FkType[] = args.map((arg) =>
          typeof arg === "object"
            ? ((arg as SourceRecord)[record.idKeys[0]] as FkType)
            : arg
        ) as any;
        const records = await this._primeAll(
          await this.repo.table().whereIn(foreignKey as any, ids as any[])
        );
        const table = keyBy<SavedDestType>(records, foreignKey as any);
        const ordered = ids.map((id) => table[(id as any).toString()]);
        return ordered;
      },
      {
        cacheKeyFn: stringify,
      }
    );
  }

  /** Analogous to belongs_to in Rails */
  owning<
    UnsavedSource,
    SavedSource,
    IdType extends object,
    ForeignKey extends keyof SavedSource
  >(
    record: KnexRecordInfo<UnsavedSource, SavedSource, IdType>,
    sourceKey: ForeignKey
  ) {
    if (record.idKeys.length > 1) {
      throw new Error("owning doesn't support compound primary keys");
    }
    type FkType = SavedSource[ForeignKey];
    type Filter<T, U> = T extends U ? T : never;
    // Result is nullable if the foreign key is nullable or undefined. Else non-nullable.
    type ResultType = Filter<FkType, null | undefined> extends never
      ? SavedDestType
      : null | SavedDestType;

    return new DataLoader<
      Pick<SavedSource, ForeignKey> | IdType[keyof IdType],
      ResultType
    >(
      async (sourceIdOrSourceRecords) => {
        const sourceRecordsToFindById = sourceIdOrSourceRecords.filter(
          (arg) => typeof arg !== "object"
        ) as any;

        const sourceRecordsFromIds = await this.repo.db
          .table(record.tableName)
          .whereIn(record.idKeys[0].toString(), sourceRecordsToFindById);

        const sourceIdRecordTable = keyBy<any>(
          sourceRecordsFromIds,
          idKeysOf(record as any)[0]
        );

        const destIdOrNullForMissingRelations: (FkType | null)[] =
          sourceIdOrSourceRecords.map((arg: any) =>
            typeof arg === "object"
              ? arg[sourceKey]
              : sourceIdRecordTable[arg][sourceKey]
          );

        const records: any[] = await this.repo.findById.loadMany(
          compact(destIdOrNullForMissingRelations) as any[]
        );

        const destIdToRecordTable = keyBy<SavedDestType | null>(
          records,
          idKeysOf(record as any)[0]
        );
        const resultsInInputOrder = destIdOrNullForMissingRelations.map(
          (destId) =>
            destId ? destIdToRecordTable[(destId as any).toString()] : null
        );
        return resultsInInputOrder as any;
      },
      {
        cacheKeyFn: stringify as any,
      }
    );
  }

  /** Given a set of records for this repo type, prime all of them into the findById dataloader and return whichever records it stores. (Prime doesn't replace existing entries, so we want what's in there) */
  private async _primeAll(rows: any[]): Promise<any[]> {
    for (const row of rows) {
      this.repo.find.prime(this.repo.recordType.idOf(row), row);
    }
    const ids = rows.map((row) => this.repo.recordType.idOf(row));

    // Return the actual objects from the findById loader
    // instead of caching multiple copies of the same record
    return await this.repo.find.loadMany(ids);
  }
}

/** Factory to construct a DataLoader for associations returning the destination type handled by the passed in repository */
export function loaderOf<
  TContext extends MinimalContext,
  TRecInfo extends KnexRecordInfo
>(repo: KnexRepositoryBase<TContext, TRecInfo>) {
  return new LoaderFactory<
    TContext,
    UnsavedR<TRecInfo>,
    SavedR<TRecInfo>,
    KeyType<TRecInfo>
  >(repo as any);
}

export abstract class TableHelpers<
  TContext extends MinimalContext,
  TUnsavedR,
  TSavedR extends object,
  IdKeyT extends object
> {
  abstract recordType: KnexRecordInfo<TUnsavedR, TSavedR, IdKeyT>;
  public abstract db: Knex;

  table() {
    return this.db.table(this.recordType.tableName);
  }

  prepToCreate(unsaved: TUnsavedR): Partial<TSavedR> {
    const idKeys = idKeysOf(this.recordType as any);

    return _.omit(unsaved as any, idKeys[0]) as any;
  }

  async insert(unsaved: TUnsavedR): Promise<TSavedR> {
    const idKeys = idKeysOf(this.recordType as any);

    await this.table().insert(this.prepToCreate(unsaved));

    const identityResult: { currentIdentity: number } | undefined = _.first(
      await this.db.raw(
        `SELECT IDENT_CURRENT('${this.recordType.tableName}') AS currentIdentity`
      )
    );

    if (!identityResult) {
      throw new Error(
        `Unable to determine ${this.recordType.tableName} record identity`
      );
    }

    const identity = identityResult.currentIdentity;

    return {
      ...unsaved,
      [idKeys[0]]: identity,
    } as unknown as TSavedR;
  }

  async insertMany(unsavedRecords: TUnsavedR[]): Promise<TSavedR[]> {
    const idKeys = idKeysOf(this.recordType as any);
    const saved: TSavedR[] = [];

    const prep = this.prepToCreate.bind(this);

    const chunkSize = 1000;

    const unsavedRecordChunks = _.chunk(unsavedRecords.map(prep), chunkSize);

    for (const unsavedRecordsChunk of unsavedRecordChunks) {
      const fieldNames = Object.keys(unsavedRecordsChunk[0]);
      const rawRecords = unsavedRecordsChunk.map((unsavedRecord) => {
        const rawRecord = fieldNames
          .map((fieldName) => {
            const value = (unsavedRecord as any)[fieldName];

            const sqlString = escapeSqlString(value);
            return escapeBindingSyntax(sqlString);
          })
          .join(", ");

        return `(${rawRecord})`;
      });

      const rawFields = fieldNames.join(", ");
      const rawRecordset = rawRecords.join(", ");

      const rawInsert = `INSERT INTO ${this.recordType.tableName} (${rawFields}) VALUES ${rawRecordset}`;

      await this.db.raw(rawInsert);
      const identityResult: { currentIdentity: number } | undefined = _.first(
        await this.db.raw(
          `SELECT IDENT_CURRENT('${this.recordType.tableName}') AS currentIdentity`
        )
      );

      if (!identityResult) {
        throw new Error(
          `Unable to determine ${this.recordType.tableName} record identity`
        );
      }

      const latestIdentity = identityResult.currentIdentity;

      const ids = _.range(
        latestIdentity + 1 - unsavedRecordsChunk.length,
        latestIdentity + 1
      );

      saved.push(
        ...unsavedRecordsChunk.map((unsaved, index) => {
          return {
            ...unsaved,
            [idKeys[0]]: ids[index],
          } as unknown as TSavedR;
        })
      );

      if (process.env.NODE_ENV === "development") {
        console.info(
          "✅ inserted",
          unsavedRecordsChunk.length,
          "records,",
          saved.length,
          "of",
          unsavedRecords.length,
          "total"
        );
      }
    }

    return saved;
  }

  async update(attrs: TSavedR): Promise<TSavedR> {
    let records: TSavedR[];
    try {
      const idConstraint = this.recordType.idOf(attrs);
      records = await this.table()
        .where(idConstraint)
        .update(_.omit(attrs, Object.keys(idConstraint)), "*");
    } catch (err) {
      throw new Error(err.message);
    }
    const updatedRecord = records[0] as TSavedR;
    if (updatedRecord) {
      return updatedRecord;
    } else {
      throw new Error("Could not find record");
    }
  }

  async delete(...ids: KeyType<KnexRecordInfo<TUnsavedR, TSavedR, IdKeyT>>[]) {
    try {
      await this.table()
        .whereIn(idKeysOf(this.recordType as any), ids as any)
        .delete();
    } catch (err) {
      throw new Error(err.message);
    }
  }

  async all(opts?: {
    orderBy?: Array<
      | keyof TSavedR
      | Readonly<{ column: keyof TSavedR; order?: "asc" | "desc" }>
    >;
  }): Promise<TSavedR[]> {
    if (opts && opts.orderBy) {
      return await this.table().orderBy(opts.orderBy as any);
    }

    return await this.table();
  }

  async first(): Promise<TSavedR | null> {
    return (await this.table().limit(1))[0] || null;
  }

  async count(): Promise<number> {
    return (await this.table().count())[0][""] as any;
  }

  find = new DataLoader<
    KeyType<KnexRecordInfo<TUnsavedR, TSavedR, IdKeyT>>,
    TSavedR | null
  >(
    async (ids) => {
      const idKeys = idKeysOf(this.recordType);
      const rows: TSavedR[] = await this.table().whereIn(
        idKeys as any,
        ids.map((id) => at(id as any, idKeys)) as any
      );
      const toKey = (row: any) => stringify(at(row as any, idKeys));
      const byId = keyBy(rows, toKey);
      return ids.map((id) => byId[toKey(id)]);
    },
    { cacheKeyFn: stringify as any }
  );

  findById = new DataLoader<IdKeyT[keyof IdKeyT], TSavedR | undefined>(
    async (ids) => {
      if (idKeysOf(this.recordType).length !== 1) {
        throw new Error(
          "findById doesn't currently work with composite primary keys"
        );
      }
      const rows: TSavedR[] = await this.table().whereIn("UserID", ids as any);
      const byId = keyBy(rows, "UserID");
      return ids.map((id) => byId[(id as any).toString()]);
    },
    {
      cacheKeyFn: stringify as any,
    }
  );
}

export abstract class RepositoriesBase {
  constructor(protected ctx: MinimalContext) {}

  // private _repoLookupMap: null | Map<
  //   KnexRecordInfo<any, any, any>,
  //   KnexRepositoryBase<any, any>
  // > = null;

  transaction(
    func: (repos: this, transaction: knex.Knex.Transaction) => Promise<any>,
    isolationLevel: IsolationLevel = "READ COMMITTED"
  ): Promise<any> {
    // eslint-disable-next-line @typescript-eslint/no-misused-promises
    return new Promise(async (resolve, reject) => {
      try {
        const result = await this.ctx
          .get(KnexPort)
          .transaction(async (trx: any) => {
            if (isolationLevel !== "READ COMMITTED") {
              await trx.raw(
                `SET TRANSACTION ISOLATION LEVEL ${isolationLevel}`
              );
            }
            return await func(
              new (this as any).constructor(
                this.ctx.clone((b) => b.add(KnexPort, () => trx))
              ),
              trx
            );
          });

        resolve(result);
      } catch (e) {
        reject(e);
      }
    });
  }

  domain<T extends any>(
    domain: Domain,
    func: (repos: this) => Promise<T>
  ): Promise<T> {
    // eslint-disable-next-line @typescript-eslint/no-misused-promises
    return new Promise(async (resolve, reject) => {
      try {
        const dbInstance = db.getConnection(domain);

        const result = await func(
          new (this as any).constructor(
            this.ctx.clone((b) => b.add(KnexPort, () => dbInstance))
          )
        );

        resolve(result);
      } catch (e) {
        reject(e);
      }
    });
  }
}

export interface KnexRepositoryBase<
  TContext extends MinimalContext,
  TRecordInfo extends KnexRecordInfo
> extends TableHelpers<
    TContext,
    UnsavedR<TRecordInfo>,
    SavedR<TRecordInfo>,
    KeyType<TRecordInfo>
  > {
  _recordType: TRecordInfo;
}

export type RepoRecordType<Repo extends KnexRepositoryBase<any, any>> =
  Repo extends KnexRepositoryBase<any, infer Rec> ? Rec : never;

export function UnboundRepositoryBase<
  TRecordInfo extends KnexRecordInfo,
  TContext extends MinimalContext = MinimalContext
>(aRecordType: TRecordInfo) {
  return class Repository
    extends TableHelpers<
      TContext,
      UnsavedR<TRecordInfo>,
      SavedR<TRecordInfo>,
      KeyType<TRecordInfo>
    >
    implements KnexRepositoryBase<TContext, TRecordInfo>
  {
    _recordType!: TRecordInfo;
    static readonly recordType = aRecordType;
    static readonly tableName = aRecordType.tableName;
    public readonly recordType = aRecordType;

    constructor(protected ctx: TContext) {
      super();
    }

    get db() {
      return this.ctx.get(KnexPort);
    }
  };
}
